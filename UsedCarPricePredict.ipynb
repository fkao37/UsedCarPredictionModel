{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used Car Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buying a used car is a daunting experience fraught with challenges. In addition to the hidden issues such as past accidents, mechanical and maintenance problems, the buying process involves navigating through various options, which is not only daunting and time consuming with no guarantee of a positive outcome. Certain car-knowledge domain expertize is typically needed to make an inform decision to better improvement for a positive purchase outcome.\n",
    "This project presents a ML Model that can used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From the business perspective, the profitability of the used car business hinges on acquiring well-maintained vehicles, precisely evaluating their worth, and providing competitive prices.\n",
    "\n",
    "A crucial aspect of the used car business is the detailed identification of key features that determine the price of a used car. Factors such as the vehicle's wear and tear measured using its age, mileage, condition, and service history play a significant role in its valuation. The make and model of the car, its popularity, and regional market demand also influence the price.\n",
    "\n",
    "From the consumer perspective, especially for those typically lacking the car domain-specific expertise, the ability to make an inform purchase resulting in an positive and happy outcome is of great importance for future purchases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet\n",
    "\n",
    "The dataset is a tabular, comma delimited, excel (.csv) file, where each row represents a specific used car listing, and each columns represents the specific feature or attribute for the car.\n",
    "\n",
    "### Data Source:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Filename</th>\n",
    "        <th>Type</th>\n",
    "        <th>Number of Rows</th>\n",
    "        <th>Number of Features</th>\n",
    "        <th>Delimiter</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>'data/vehicle.csv'</td>\n",
    "        <td>Excel csv</td>\n",
    "        <td>426,880</td>\n",
    "        <td>18</td>\n",
    "        <td>,</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "### Features:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Feature</th>\n",
    "        <th>Type</th>\n",
    "        <th>Description</th>\n",
    "        <th>Sample Values</th>\n",
    "        <th>Unique Values</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>id</td>\n",
    "        <td>Numeric</td>\n",
    "        <td>assigned vehicle ID</td>\n",
    "        <td>7222695916, ...</td>\n",
    "        <td>426880</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>region</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle roaming area</td>\n",
    "        <td>hudson valley, el passo, ...</td>\n",
    "        <td>426880</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>price</td>\n",
    "        <td>Numeric</td>\n",
    "        <td>Vehicle Listed Price\n",
    "        <td>21000, 15,995, ...</td>\n",
    "        <td>426880</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>year</td>\n",
    "        <td>Numeric</td>\n",
    "        <td>Manufacture year of the vehicle\n",
    "        <td>2014, 2018, ...</td>\n",
    "        <td>425675</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>manufacturer</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle manufacturer</td>\n",
    "        <td>gmc, chevrolet, toyota, ...</td>\n",
    "        <td>409234</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>model</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle model\n",
    "        <td>f-150 xlt, tacoma, cherokee</td>\n",
    "        <td>421603</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>condition</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle condition</td>\n",
    "        <td>good, excellent, ...</td>\n",
    "        <td>252776</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>cylinders</td>\n",
    "        <td>String</td>\n",
    "        <td>Number of engine cylinders</td>\n",
    "        <td>8 cylinders, 6 cylinders, ...</td>\n",
    "        <td>249202</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>fuel</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle fuel type</td>\n",
    "        <td>gas, diesel, ...</td>\n",
    "        <td>423867</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>odometer</td>\n",
    "        <td>Numeric</td>\n",
    "        <td>Milage driven in miles</td>\n",
    "        <td>12102, 80328, ...</td>\n",
    "        <td>422480</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>title_status</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle title status</td>\n",
    "        <td>clean, rebuilt, ...</td>\n",
    "        <td>418638</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>transmission</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle transmission type</td>\n",
    "        <td>automatic, manual, ...</td>\n",
    "        <td>424324</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>VIN</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle Identification Number</td>\n",
    "        <td>5TFTX4CN6CX015282, ...</td>\n",
    "        <td>265838</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>drive</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle Drive type</td>\n",
    "        <td>fwd, rwd, ...</td>\n",
    "        <td>296313</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>size</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle Size Classification\n",
    "        <td>mid-size, full-size, ...</td>\n",
    "        <td>120519</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>type</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle type classification</td>\n",
    "        <td>pickup, SUV, truck, ...</td>\n",
    "        <td>334022</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>paint_color</td>\n",
    "        <td>String</td>\n",
    "        <td>Vehicle Color</td>\n",
    "        <td>white, red, blue, ...</td>\n",
    "        <td>296677</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>state</td>\n",
    "        <td>String</td>\n",
    "        <td>Abbreviated lower case of each state where the vehicle is registered\n",
    "        <td>ma, ca, or, ...</td>\n",
    "        <td>426880</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Data Cleaning \n",
    "#   - Remove null rows (for any field)\n",
    "#   - Remove No price listed (incomplete price listing)\n",
    "\n",
    "df_vehicle_ = pd.read_csv('data/vehicles.csv')\n",
    "print(df_vehicle_.info())\n",
    "print()\n",
    "# drop unreasonable price == 0\n",
    "df_vehicle = df_vehicle_[ df_vehicle_['price'] > 0 ].dropna()\n",
    "df_vehicle = df_vehicle.dropna()\n",
    "print(df_vehicle.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "This step prepares the data for modeling.  Only valid data are allowed to proceed:\n",
    "1.  Remove missing, null.\n",
    "2.  Remove bad data, where price = 0\n",
    "3.  Standardize the entire dataset to 'lower case'\n",
    "4.  Remove unusable features\n",
    "\n",
    "<table>\n",
    "    <th>Usable Rows</th>\n",
    "    <th>32,496</th>\n",
    "    <th>Features</th>\n",
    "    <th>18</th>\n",
    "</table>\n",
    "\n",
    "This section analyze the dataset's features and evaluates the correlations and influences of each feature against the target feature.  \n",
    "\n",
    "* target feature: price\n",
    "\n",
    "The id, and VIN features are independent of the vehicle price as they are unique for each car, and are removed from the dataset.\n",
    "\n",
    "Furthermore, with the objective to reduce the number of features to use for regression, a <b>Mutual Information Score</b> is performed for every feature vs the target feature: price, and shown in the following diagram.  A odometer reading cluster breakdown vs car price is also shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module: make_mi_scores(), plot_mi_scores()\n",
    "\n",
    "make_mi_scores():  Compute the Mutual Importance between the data frame's features and the target\n",
    "                   The computed score is returned\n",
    "\n",
    "plot_mi_scores():  Plot the computed Mutual Importance Scores between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Compute Mutual Importance Score between Features and the Target\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(title,scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.xlabel('score')\n",
    "    plt.grid(True)\n",
    "    title_ = \"Mutual Information Scores VS \" + title\n",
    "    plt.title( title_ )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ranger encoder, encode data to a pre-assigned value for each range specified\n",
    "def encode_range( df, feature, data_ranges ):\n",
    "#    print(f'encode_range: type: {type(df[feature])}, name: {feature}')\n",
    "    def map_to_ordinal( value ):\n",
    "        for i,r in enumerate(data_ranges, start=1):\n",
    "            if r[0] <= value <= r[1]:\n",
    "                return i\n",
    "\n",
    "        return len(data_ranges)  # case value outside of range\n",
    "    \n",
    "    df[feature+\"_encoded\"] = df[feature].apply(map_to_ordinal)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: run_model\n",
    "\n",
    "A module that performs the GridSerachCV with the hyper-parameters supplied to find the best estimator with the best score.  The module assumes that the numeric columns has already been standardized, and does not perform any further scaling.\n",
    "The model's pipeline consists of the following steps:\n",
    "1. training / development / testing data split: 80%, 15%, 5%\n",
    "1. generate PolynomialFeatures from the data's features based on the hyper-parameter supplied\n",
    "2. perform SequentialFeatureSelector, using LinearRegression as the estimator, and iterate with the hyper-parameters supplied\n",
    "3. perform model regularization based on the \"regressor\" specified\n",
    "\n",
    "GridSearchCV is configured with:\n",
    "1. PolynomialFeatures degrees: [1,2,3]\n",
    "2. SequentialFeatureSelector's n_features_to_select: [3,5,9]\n",
    "4. Regularization Alpha: [0.01,0.1,1.0,5.0,10.0]\n",
    "5. K-Fold validation with cv = 5\n",
    "6. r2 is used as the scoring method\n",
    "\n",
    "The module returns the best_estimator, best_esimator's coef and the grid_search object back to the calling routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model the entire USA\n",
    "#\n",
    "from collections import defaultdict\n",
    "\n",
    "nation_models       = defaultdict()\n",
    "nation_gmodels      = defaultdict()\n",
    "nation_model_coef   = defaultdict()\n",
    "df_vehicle = df_vehicle.dropna(axis=1)\n",
    "\n",
    "print(f'\\n\\n##########   National Model   ##########\\n')\n",
    "X  = df_vehicle.copy()\n",
    "X0 = df_vehicle.copy()\n",
    "Z  = X.copy()\n",
    "y  = df_vehicle['price'].copy()\n",
    "\n",
    "# cleanup Odometer column to ensure all numeric values\n",
    "X['odometer'] = pd.to_numeric( X['odometer'],errors='coerce' )\n",
    "odo_ranges_encoding = [\n",
    "    (0, 9999),\n",
    "    (10000,29999),\n",
    "    (30000,49999),\n",
    "    (50000,69999),\n",
    "    (70000,99999),\n",
    "    (100000,149999),\n",
    "    (150000,199999),\n",
    "    (200000,249999),\n",
    "    (250000,999999)\n",
    "]\n",
    "odo_features = ['0-9,999', '10,000-29,999','30,000-49,999','50,000-69,999','70,000-99,999','100,000-149,999','150,000-199,999','200,000-249,999','250,000-999,999']\n",
    "odo_range = {\n",
    "    '0-9999' : (0, 9999),\n",
    "    '10000-29999'   : (10000, 29999),\n",
    "    '30000-49999'   : (30000,49999),\n",
    "    '50000-69999'   : (50000,69999),\n",
    "    '70000-99999'   : (70000,99999),\n",
    "    '100000-149999' : (100000,149999),\n",
    "    '150000-199999' : (150000,199999),\n",
    "    '200000-249999' : (200000,249999),\n",
    "    '250000-1000000': (250000,1000000)\n",
    "}\n",
    "\n",
    "features_target    = ['price']\n",
    "features_untouched = ['year']\n",
    "features_target    = ['price']\n",
    "features_ordinal   = ['state','model','transmission','drive','size','condition', 'cylinders','title_status','manufacturer','paint_color','fuel','type']\n",
    "features_onehot    = []\n",
    "features_label     = []\n",
    "features_numeric   = ['year']\n",
    "features_range     = ['odometer']\n",
    "\n",
    "ordinal_transformer  = Pipeline(steps=[ ('ordinal', OrdinalEncoder()) ])\n",
    "onehot_transformer   = Pipeline(steps=[ ('onehot',  OneHotEncoder() ) ])\n",
    "label_transformer    = Pipeline(steps=[ ('label',   LabelEncoder()  ) ])\n",
    "numeric_transformer  = FunctionTransformer( lambda x: x)\n",
    "identify_transformer = FunctionTransformer( lambda x: x)\n",
    "copy_transformer     = FunctionTransformer( lambda x: x)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "    ('num',     copy_transformer,    features_numeric ),\n",
    "    ('range',   copy_transformer,    features_range   ),\n",
    "    ('ord',     ordinal_transformer, features_ordinal ),\n",
    "#    ('onehot',  onehot_transformer,  features_onehot  ),\n",
    "])\n",
    "\n",
    "X1 = preprocessor.fit_transform(X)\n",
    "X1_dense = X1.copy()\n",
    "#onehot_features = list(preprocessor.named_transformers_['onehot'].named_steps['onehot'].get_feature_names_out(input_features=features_onehot))\n",
    "\n",
    "all_features = features_numeric + features_range + features_ordinal \n",
    "try:\n",
    "    X2 = pd.DataFrame(X1_dense, columns=all_features)\n",
    "    X2 = encode_range(X2, 'odometer', odo_ranges_encoding)\n",
    "    X2 = X2.drop(columns=features_range)\n",
    "    y2 = y.copy()\n",
    "#    print(f'X2: {X2.columns}, {X2.shape}, \\n{X2.head(10)}')\n",
    "except ValueError as e:\n",
    "    print(f'Error creating DataFrame: {e}')\n",
    "    X2 = None\n",
    "\n",
    "#####from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "###### Data Ready \n",
    "###### Run Model\n",
    "param_grid = {\n",
    "    'regressor__alpha': np.logspace(-3, 3, 3),  # alpha values for Ridge regression\n",
    "    'regressor__max_iter' : [ 10 ]\n",
    "}\n",
    "print(f'X2: {X2.info()}\\n{X2.head(5)}')\n",
    "#regressor = Ridge()\n",
    "regressor = Lasso()\n",
    "ridge_model, ridge_coef, gridsearch_model = run_model_Z_1( X2, y2, 'Ridge', regressor, param_grid)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from collections import defaultdict\n",
    "def run_model( df, df_target, model_name, base_model, param_grid ):\n",
    "    \n",
    "    X = df_ = df.copy()\n",
    "    y = df_target.copy()\n",
    "    \n",
    "    X_train, X_combo, y_train, y_combo = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_dev,   X_test,  y_dev,   y_test  = train_test_split(X_combo, y_combo, test_size=0.05, random_state=42)\n",
    "\n",
    "    print(f'************  Model: {model_name}  **************')\n",
    "\n",
    "    pgrid = {\n",
    "        'pfeatures__degree':[1,2,3],  #[2,3]\n",
    "        'feature_selector__n_features_to_select': [3,5,9],  #[3,5]\n",
    "        'feature_selector__direction' : ['forward'],\n",
    "        'regressor__alpha': [0.01,0.1,1.0,5.0,10.0]  #[0.1,1.0,10.0]\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('pfeatures',PolynomialFeatures(include_bias=False)),\n",
    "        ('feature_selector',SequentialFeatureSelector(estimator=LinearRegression())),\n",
    "        ('regressor', base_model)\n",
    "    ])\n",
    "    grid_search = GridSearchCV(pipeline, pgrid, cv=5, scoring='r2', error_score='raise')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "        \n",
    "    y_dev_preds  = grid_search.predict(X_dev )\n",
    "    y_test_preds = grid_search.predict(X_test)\n",
    "\n",
    "    mse_y_dev  = mean_squared_error( y_dev_preds,  y_dev  )\n",
    "    mse_y_test = mean_squared_error( y_test_preds, y_test )\n",
    "\n",
    "    best_model           = grid_search.best_estimator_\n",
    "    best_model_coef      = best_model.named_steps['regressor'].coef_\n",
    "    best_model_intercept = best_model.named_steps['regressor'].intercept_\n",
    "    best_model_features  = best_model.named_steps['feature_selector'].get_support()\n",
    "    \n",
    "    poly_feature_names = best_model.named_steps['pfeatures'].get_feature_names_out(input_features=X.columns)\n",
    "    # Select the names of the selected features\n",
    "    selected_feature_names = np.array(poly_feature_names)[best_model_features]\n",
    "    print(f'selected_feature_names: {selected_feature_names}, Coef: {best_model_coef}')\n",
    "\n",
    "    coef_df = pd.DataFrame({'Feature': selected_feature_names, 'Coefficient': best_model_coef[0]})\n",
    "    \n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"Best r2 score:\", grid_search.best_score_)\n",
    "    #    print(f'mse-y_dev : {mse_y_dev}')\n",
    "    #    print(f'mse-y_test: {mse_y_test}')\n",
    "    print(f'{coef_df}')\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot Ridge regression resultsu8\n",
    "    ridge_alphas = [params['regressor__alpha'] for params in grid_search.cv_results_['params']]\n",
    "    ridge_mse = -grid_search.cv_results_['mean_test_score']\n",
    "    plt.plot(ridge_alphas, ridge_mse, marker='o', label='Ridge')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.title(f'{model_name} Regression')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model, coef_df, grid_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Mutual Importance Scores\n",
    "\n",
    "This is the first step in understanding the data content and how each feature is related to the target feature.  All none numeric fields are label encoded.  The odometer feature is range encoded for group computation.\n",
    "\n",
    "From the Mutual Importance score, and not surprising, the odometer, the model, and the year of the vehicle are the top features that influences the price of the car.  \n",
    "Vehicle with lower odometer milages tend to have higher prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Modeling Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "target_feature = 'price'\n",
    "\n",
    "X = df_vehicle.copy()\n",
    "Z = df_vehicle.copy()\n",
    "X = X.drop(columns=[target_feature,'VIN','id'])\n",
    "y = df_vehicle[target_feature]\n",
    "\n",
    "for colname in X.select_dtypes(\"object\"):\n",
    "    X[colname], _ = X[colname].factorize()\n",
    "\n",
    "# All discrete features should now have integer dtypes (double-check this before using MI!)\n",
    "discrete_features = X.dtypes == int\n",
    "mi_scores = make_mi_scores(X, y, discrete_features)\n",
    "mi_scores[::3]  # show a few features with their MI scores\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(target_feature,mi_scores)\n",
    "plt.savefig('images/mi_scores.png')\n",
    "\n",
    "X_odo = X[ 'odometer' ]\n",
    "# cleanup Odometer column to ensure all numeric values\n",
    "X['odometer'] = pd.to_numeric( X['odometer'],errors='coerce' )\n",
    "odo_ranges_encoding = [\n",
    "    (0, 9999),\n",
    "    (10000,29999),\n",
    "    (30000,49999),\n",
    "    (50000,69999),\n",
    "    (70000,99999),\n",
    "    (100000,149999),\n",
    "    (150000,199999),\n",
    "    (200000,249999),\n",
    "    (250000,999999)\n",
    "]\n",
    "odo_features = ['0-9,999', '10,000-29,999','30,000-49,999','50,000-69,999','70,000-99,999','100,000-149,999','150,000-199,999','200,000-249,999','250,000-999,999']\n",
    "odo_range = {\n",
    "    '0-9999' : (0, 9999),\n",
    "    '10000-29999'   : (10000, 29999),\n",
    "    '30000-49999'   : (30000,49999),\n",
    "    '50000-69999'   : (50000,69999),\n",
    "    '70000-99999'   : (70000,99999),\n",
    "    '100000-149999' : (100000,149999),\n",
    "    '150000-199999' : (150000,199999),\n",
    "    '200000-249999' : (200000,249999),\n",
    "    '250000-1000000': (250000,1000000)\n",
    "}\n",
    "X_odo = encode_range( Z, 'odometer', odo_ranges_encoding )\n",
    "##print(f'\\n\\n{X_odo.columns}')\n",
    "##print(f'\\n{X_odo.head(10)}')\n",
    "\n",
    "plot = sns.lmplot(data=X_odo,x='odometer_encoded',y='price')\n",
    "plot.set(xticks=range(len(odo_features)),xticklabels=odo_features)\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('images/odometer_range_price.png')\n",
    "plt.show()\n",
    "\n",
    "X_model = X_odo.groupby('model')['model'].count()\n",
    "\n",
    "car_models, n_car_models = np.unique(X_odo['model'],return_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Prediction Model\n",
    "1. Column Transformer Pipeline\n",
    "    a. Range Encode the 'odometer' feature for standardization\n",
    "    b. Ordinal Encode the non-numeric fields with each unique values assigned on first-come-first-serve basis\n",
    "    c. drop features id, VIN from data frame\n",
    "2. Run model pipeline, selecting Ridge(), and Lasso() and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "## Model the entire USA\n",
    "#\n",
    "from collections import defaultdict\n",
    "\n",
    "nation_models       = defaultdict()\n",
    "nation_gmodels      = defaultdict()\n",
    "nation_model_coef   = defaultdict()\n",
    "df_vehicle = df_vehicle.dropna(axis=1)\n",
    "\n",
    "print(f'\\n\\n####################   National Model   ####################\\n')\n",
    "X  = df_vehicle.copy()\n",
    "X0 = df_vehicle.copy()\n",
    "Z  = X.copy()\n",
    "y  = df_vehicle['price'].copy()\n",
    "\n",
    "# cleanup Odometer column to ensure all numeric values\n",
    "X['odometer'] = pd.to_numeric( X['odometer'],errors='coerce' )\n",
    "odo_ranges_encoding = [\n",
    "    (0, 9999),\n",
    "    (10000,29999),\n",
    "    (30000,49999),\n",
    "    (50000,69999),\n",
    "    (70000,99999),\n",
    "    (100000,149999),\n",
    "    (150000,199999),\n",
    "    (200000,249999),\n",
    "    (250000,999999)\n",
    "]\n",
    "odo_features = ['0-9,999', '10,000-29,999','30,000-49,999','50,000-69,999','70,000-99,999','100,000-149,999','150,000-199,999','200,000-249,999','250,000-999,999']\n",
    "odo_range = {\n",
    "    '0-9999' : (0, 9999),\n",
    "    '10000-29999'   : (10000, 29999),\n",
    "    '30000-49999'   : (30000,49999),\n",
    "    '50000-69999'   : (50000,69999),\n",
    "    '70000-99999'   : (70000,99999),\n",
    "    '100000-149999' : (100000,149999),\n",
    "    '150000-199999' : (150000,199999),\n",
    "    '200000-249999' : (200000,249999),\n",
    "    '250000-1000000': (250000,1000000)\n",
    "}\n",
    "\n",
    "features_target    = ['price']\n",
    "features_untouched = ['year']\n",
    "features_target    = ['price']\n",
    "features_ordinal   = ['state','model','transmission','drive','size','condition', 'cylinders','title_status','manufacturer','paint_color','fuel','type']\n",
    "features_onehot    = []\n",
    "features_label     = []\n",
    "features_numeric   = ['year']\n",
    "features_range     = ['odometer']\n",
    "\n",
    "ordinal_transformer  = Pipeline(steps=[ ('ordinal', OrdinalEncoder()) ])\n",
    "onehot_transformer   = Pipeline(steps=[ ('onehot',  OneHotEncoder() ) ])\n",
    "label_transformer    = Pipeline(steps=[ ('label',   LabelEncoder()  ) ])\n",
    "numeric_transformer  = FunctionTransformer( lambda x: x)\n",
    "identify_transformer = FunctionTransformer( lambda x: x)\n",
    "copy_transformer     = FunctionTransformer( lambda x: x)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "    ('num',     copy_transformer,    features_numeric ),\n",
    "    ('range',   copy_transformer,    features_range   ),\n",
    "    ('ord',     ordinal_transformer, features_ordinal ),\n",
    "])\n",
    "\n",
    "X1 = preprocessor.fit_transform(X)\n",
    "X1_dense = X1.copy()\n",
    "\n",
    "all_features = features_numeric + features_range + features_ordinal \n",
    "try:\n",
    "    X2 = pd.DataFrame(X1_dense, columns=all_features)\n",
    "    X2 = encode_range(X2, 'odometer', odo_ranges_encoding)\n",
    "    X2 = X2.drop(columns=features_range)\n",
    "    y2 = y.copy()\n",
    "except ValueError as e:\n",
    "    print(f'Error creating DataFrame: {e}')\n",
    "    X2 = None\n",
    "\n",
    "param_grid = {\n",
    "    'regressor__alpha': np.logspace(-3, 3, 3),  # alpha values for Ridge regression\n",
    "    'regressor__max_iter' : [ 10 ]\n",
    "}\n",
    "\n",
    "ridge_model, ridge_coef, gridsearch_model_ridge = run_model( X2, y2, 'Ridge', Ridge(), param_grid)\n",
    "lasso_model, lasso_coef, gridsearch_model_lasso = run_model( X2, y2, 'Lasso', Lasso(), param_grid)\n",
    "    \n",
    "####################################### TBSplit #############################\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create model for each state and calculate fit score\n",
    "us_states = df_vehicle['state'].unique()\n",
    "\n",
    "\n",
    "state_ridge_models = defaultdict()\n",
    "ridge_gmodels      = defaultdict()\n",
    "model_ridge_coef   = defaultdict()\n",
    "\n",
    "state_lasso_models = defaultdict()\n",
    "lasso_gmodels      = defaultdict()\n",
    "model_lasso_coef   = defaultdict()\n",
    "\n",
    "df_vehicle = df_vehicle.dropna(axis=1)\n",
    "for state in us_states:\n",
    "    print(f'\\n\\n##############################   {state}   ##############################\\n')\n",
    "    X  = df_vehicle[ df_vehicle['state'] == state ].copy()\n",
    "    X0 = df_vehicle[ df_vehicle['state'] == state ].copy()\n",
    "    Z  = X.copy()\n",
    "    y  = df_vehicle[ df_vehicle['state'] == state ]['price'].copy()\n",
    "\n",
    "    # cleanup Odometer column to ensure all numeric values\n",
    "    X['odometer'] = pd.to_numeric( X['odometer'],errors='coerce' )\n",
    "    odo_ranges_encoding = [\n",
    "        (0, 9999),\n",
    "        (10000,29999),\n",
    "        (30000,49999),\n",
    "        (50000,69999),\n",
    "        (70000,99999),\n",
    "        (100000,149999),\n",
    "        (150000,199999),\n",
    "        (200000,249999),\n",
    "        (250000,999999)\n",
    "    ]\n",
    "    odo_features = ['0-9,999', '10,000-29,999','30,000-49,999','50,000-69,999','70,000-99,999','100,000-149,999','150,000-199,999','200,000-249,999','250,000-999,999']\n",
    "    odo_range = {\n",
    "        '0-9999' : (0, 9999),\n",
    "        '10000-29999'   : (10000, 29999),\n",
    "        '30000-49999'   : (30000,49999),\n",
    "        '50000-69999'   : (50000,69999),\n",
    "        '70000-99999'   : (70000,99999),\n",
    "        '100000-149999' : (100000,149999),\n",
    "        '150000-199999' : (150000,199999),\n",
    "        '200000-249999' : (200000,249999),\n",
    "        '250000-1000000': (250000,1000000)\n",
    "    }\n",
    "\n",
    "    features_target    = ['price']\n",
    "    features_untouched = ['year']\n",
    "    features_target    = ['price']\n",
    "    features_ordinal   = ['state','transmission','drive','size','condition', 'cylinders','title_status','manufacturer','paint_color','fuel','type']\n",
    "    features_onehot    = []\n",
    "    features_numeric   = ['year']\n",
    "    features_range     = ['odometer']\n",
    "\n",
    "    ordinal_transformer  = Pipeline(steps=[ ('ordinal', OrdinalEncoder()) ])\n",
    "    onehot_transformer   = Pipeline(steps=[ ('onehot',  OneHotEncoder() ) ])\n",
    "    label_transformer    = Pipeline(steps=[ ('label',   LabelEncoder()  ) ])\n",
    "    numeric_transformer  = FunctionTransformer( lambda x: x)\n",
    "    identify_transformer = FunctionTransformer( lambda x: x)\n",
    "    copy_transformer     = FunctionTransformer( lambda x: x)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "        ('num',     copy_transformer,    features_numeric ),\n",
    "        ('range',   copy_transformer,    features_range   ),\n",
    "        ('ord',     ordinal_transformer, features_ordinal ),\n",
    "    ])\n",
    "\n",
    "    X1 = preprocessor.fit_transform(X)\n",
    "    X1_dense = X1.copy()\n",
    "\n",
    "    all_features = features_numeric + features_range + features_ordinal\n",
    "    try:\n",
    "        X2 = pd.DataFrame(X1_dense, columns=all_features)\n",
    "        X2 = encode_range(X2, 'odometer', odo_ranges_encoding)\n",
    "        X2 = X2.drop(columns=features_range)\n",
    "        y2 = y.copy()\n",
    "    except ValueError as e:\n",
    "        print(f'Error creating DataFrame: {e}')\n",
    "        X2 = None\n",
    "\n",
    "    param_grid = {\n",
    "        'regressor__alpha': np.logspace(-3, 3, 3),  # alpha values for Ridge regression\n",
    "        'regressor__max_iter' : [ 10 ]\n",
    "    }\n",
    "    state_model, state_coef, gridsearch_model = run_model( X2, y2, 'Ridge', Ridge(), param_grid)\n",
    "    \n",
    "    state_ridge_models[state] = state_model\n",
    "    model_ridge_coef[state]   = state_coef\n",
    "    ridge_gmodels[state]      = gridsearch_model\n",
    "\n",
    "    state_model, state_coef, gridsearch_model = run_model( X2, y2, 'Lasso', Lasso(), param_grid)\n",
    "    \n",
    "    state_lasso_models[state] = state_model\n",
    "    model_lasso_coef[state]   = state_coef\n",
    "    lasso_gmodels[state]      = gridsearch_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
